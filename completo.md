# Relat√≥rio Completo: Implementa√ß√£o de Batch Transform SageMaker com Go

Este documento registra a interatividade t√©cnica para a constru√ß√£o de uma solu√ß√£o de infer√™ncia em lote de alta performance utilizando a linguagem **Go** e a biblioteca **Leaves** (LightGBM).

---

## 1. Introdu√ß√£o e Motiva√ß√£o
A cria√ß√£o de um **Batch Transform Job** no Amazon SageMaker usando **Go** (via AWS SDK for Go v2) oferece uma alternativa de baixa lat√™ncia e alta efici√™ncia em compara√ß√£o ao ecossistema tradicional de Python. A solu√ß√£o foca na redu√ß√£o de custos operacionais na regi√£o **sa-east-1 (S√£o Paulo)**.

### Principais Ganhos:
*   **Performance:** Uso de Goroutines para processamento paralelo real (sem o gargalo do GIL do Python).
*   **Efici√™ncia de Mem√≥ria:** Consumo de RAM reduzido de ~1GB para <50MB.
*   **Custo:** Possibilidade de usar inst√¢ncias da fam√≠lia `ml.c5` (mais baratas e r√°pidas em CPU).

---

## 2. Orquestra√ß√£o com Go SDK v2
Para disparar o Job de treinamento e infer√™ncia diretamente via Go, utilizamos o m√©todo `CreateTransformJob`.

### Exemplo de Configura√ß√£o de Job:
```go
input := &sagemaker.CreateTransformJobInput{
    TransformJobName: aws.String("job-go-v1"),
    ModelName:        aws.String("meu-modelo-go"),
    MaxConcurrentTransforms: aws.Int32(20),
    MaxPayloadInMB:          aws.Int32(6),
    BatchStrategy:           types.BatchStrategyMultiRecord,
    TransformInput: &types.TransformInput{
        DataSource: &types.TransformDataSource{
            S3DataSource: &types.TransformS3DataSource{
                S3Uri: aws.String("s3://bucket/input/"),
            },
        },
        ContentType: aws.String("text/csv"),
        SplitType:   types.SplitTypeLine,
    },
    TransformResources: &types.TransformResources{
        InstanceCount: aws.Int32(1),
        InstanceType:  types.TrainingInstanceTypeMlC5Xlarge,
    },
}
```

3. O Container de Infer√™ncia Gen√©rico (Go + Leaves)
Para permitir que o time de Data Science utilize o mesmo container para m√∫ltiplos projetos, a l√≥gica de carregamento do modelo foi movida para Vari√°veis de Ambiente.
Estrat√©gia de Download Din√¢mico (S3)
O bin√°rio Go utiliza o S3 Manager para baixar o modelo em peda√ßos paralelos do S3 seguindo o padr√£o:
s3://{BUCKET}/{PROJETO_ID}/{EXPERIMENTO_ID}/model.txt
C√≥digo Completo do Servidor (main.go)
package main
```
import (
	"context"
	"encoding/csv"
	"fmt"
	"io"
	"net/http"
	"os"
	"strconv"
	"strings"

	"://github.com"
	"://github.com"
	"://github.com"
	"://github.com"
	"://github.com"
)

var (
	model     *leaves.Ensemble
	threshold float64
)

func init() {
	bucket := os.Getenv("MODEL_S3_BUCKET")
	key := os.Getenv("MODEL_S3_KEY")
	region := os.Getenv("AWS_REGION")
	if region == "" { region = "sa-east-1" }
	
	tStr := os.Getenv("PREDICTION_THRESHOLD")
	threshold, _ = strconv.ParseFloat(tStr, 64)

	localPath := "/tmp/model.txt"

	if bucket != "" && key != "" {
		fmt.Printf("[STARTUP] Baixando: s3://%s/%s\n", bucket, key)
		downloadModel(region, bucket, key, localPath)
	} else {
		localPath = "/opt/ml/model/model.txt"
	}

	var err error
	model, err = leaves.BinaryFromFile(localPath)
	if err != nil { panic(err) }
}

func downloadModel(region, bucket, key, dest string) error {
	cfg, _ := config.LoadDefaultConfig(context.TODO(), config.WithRegion(region))
	downloader := manager.NewDownloader(s3.NewFromConfig(cfg))
	f, _ := os.Create(dest)
	defer f.Close()
	_, err := downloader.Download(context.TODO(), f, &s3.GetObjectInput{
		Bucket: aws.String(bucket),
		Key:    aws.String(key),
	})
	return err
}

func invocationsHandler(w http.ResponseWriter, r *http.Request) {
	reader := csv.NewReader(r.Body)
	reader.ReuseRecord = true 
	writer := csv.NewWriter(w)
	defer writer.Flush()

	outDim := model.OutputDimension()

	for {
		record, err := reader.Read()
		if err == io.EOF { break }
		fvals := make([]float64, len(record))
		for i, str := range record {
			val, _ := strconv.ParseFloat(strings.TrimSpace(str), 64)
			fvals[i] = val
		}

		if outDim == 1 {
			res := model.PredictSingle(fvals)
			output := res
			if threshold > 0 {
				if res >= threshold { output = 1 } else { output = 0 }
			}
			writer.Write([]string{strconv.FormatFloat(output, 'f', -1, 64)})
		} else {
			preds := make([]float64, outDim)
			model.Predict(fvals, preds)
			strPreds := make([]string, outDim)
			for i, p := range preds {
				strPreds[i] = strconv.FormatFloat(p, 'f', -1, 64)
			}
			writer.Write(strPreds)
		}
	}
}

func main() {
	http.HandleFunc("/ping", func(w http.ResponseWriter, r *http.Request) { w.WriteHeader(200) })
	http.HandleFunc("/invocations", invocationsHandler)
	http.ListenAndServe(":8080", nil)
}
```

4. Infraestrutura e Docker (Multi-Stage)
O Dockerfile utiliza o est√°gio de build para gerar um bin√°rio est√°tico de apenas ~40MB, reduzindo drasticamente o tempo de "cold start" na AWS.

```
FROM golang:1.21-bullseye AS builder
WORKDIR /app
COPY go.mod go.sum ./
RUN go mod download
COPY . .
RUN CGO_ENABLED=0 go build -ldflags="-s -w" -o /server main.go

FROM debian:bullseye-slim
RUN apt-get update && apt-get install -y ca-certificates && rm -rf /var/lib/apt/lists/*
COPY --from=builder /server /usr/local/bin/server
EXPOSE 8080
ENTRYPOINT ["/usr/local/bin/server"]
```

5. Estudo Comparativo e Custos (sa-east-1)
Recurso	Python (Baseline)	Go (Proposto)
Inst√¢ncia	ml.m5.xlarge ($0.33/h)	ml.c5.large ($0.17/h)
Mem√≥ria	1GB+	< 50MB
Startup	> 1 min	< 5 segundos
Custo Final	100%	~40% do original

6. Plano de Valida√ß√£o (Sanity Check)
Para garantir que a biblioteca Leaves (Go) gera os mesmos resultados que o LightGBM original (Python):
Refer√™ncia: Gerar predi√ß√µes via script Python original.
Go Test: Processar o mesmo CSV via servidor Go.
Compara√ß√£o: Usar o script abaixo para validar a precis√£o

```
matches = np.isclose(py_preds, go_preds, atol=1e-5).mean()
print(f"Similaridade: {matches * 100:.4f}%")
```

## Para garantir que sua implementa√ß√£o em sa-east-1 n√£o apenas funcione, mas atinja o estado de "bare-metal performance", aqui est√° a lista detalhada dos gargalos latentes e os pontos de a√ß√£o para mitig√°-los:
## 1. Gargalo de I/O e Serializa√ß√£o (O mais cr√≠tico)
O custo de converter texto (CSV) para tipos num√©ricos (float64) e vice-versa √©, muitas vezes, maior que o tempo da predi√ß√£o matem√°tica do modelo.
Ponto de Trabalho: Use strconv.ParseFloat com cautela. Se o volume for extremo, considere trocar CSV por Protobuf ou Avro, que possuem desserializa√ß√£o nativa muito mais r√°pida em Go.
A√ß√£o: Ative o reader.ReuseRecord = true para evitar que o Garbage Collector (GC) precise limpar milh√µes de pequenos objetos (slices de strings) criados a cada linha lida.
## 2. Gargalo de Concorr√™ncia do SageMaker (Orquestra√ß√£o)
Se o SageMaker enviar poucas requisi√ß√µes simult√¢neas, sua CPU ficar√° ociosa, desperdi√ßando o dinheiro pago pela inst√¢ncia.
Ponto de Trabalho: O par√¢metro MaxConcurrentTransforms no CreateTransformJob.
A√ß√£o: Teste valores agressivos (inicie em 20 e suba at√© 100). O Go gerencia Goroutines com overhead m√≠nimo; o limite deve ser o saturamento da CPU da inst√¢ncia (mantenha em ~90% no CloudWatch).
## 3. Gargalo de Rede e Lat√™ncia de Payload
Requisi√ß√µes muito pequenas geram um overhead de cabe√ßalhos HTTP e negocia√ß√£o de pacotes TCP desnecess√°rio.
Ponto de Trabalho: MaxPayloadInMB e BatchStrategy: MultiRecord.
A√ß√£o: Configure o payload para o limite pr√≥ximo de 20MB. Isso garante que cada "viagem" do S3 para o seu container traga dados suficientes para manter o processador ocupado por mais tempo.
## 4. Gargalo de Mem√≥ria e Garbage Collection (GC)
O Go pode sofrer pausas de "Stop the World" se houver muitas aloca√ß√µes de mem√≥ria por segundo, o que aumenta a lat√™ncia de cauda (P99).
Ponto de Trabalho: Vari√°vel de ambiente GOGC.
A√ß√£o: Como o container de infer√™ncia √© focado em uma tarefa √∫nica, voc√™ pode definir GOGC=off (se tiver RAM sobrando) ou GOGC=200 para reduzir a frequ√™ncia da coleta de lixo, priorizando a velocidade de processamento.
## 5. Gargalo de Inicializa√ß√£o (Cold Start)
Em inst√¢ncias de Batch Transform, o tempo que o container leva para ficar pronto √© cobrado.
Ponto de Trabalho: Tamanho da imagem e carregamento do modelo.
A√ß√£o: Utilize o S3 Downloader paraleliz√°vel (que j√° inclu√≠mos no c√≥digo) para baixar o model.txt usando m√∫ltiplas conex√µes simult√¢neas. Isso √© vital em sa-east-1 para modelos grandes.
## 6. Gargalo de Tipo de Inst√¢ncia (CPU Bound)
O LightGBM (via Leaves) depende quase exclusivamente da performance de n√∫cleo √∫nico e instru√ß√µes vetoriais da CPU.
Ponto de Trabalho: Sele√ß√£o da fam√≠lia de inst√¢ncias.
A√ß√£o: Priorize inst√¢ncias C5 ou C6g (Graviton, se compilar Go para ARM). Elas possuem clock superior √†s inst√¢ncias M5 e s√£o otimizadas para c√°lculos matem√°ticos, resultando em menor custo por predi√ß√£o.
## 7. Gargalo de Escrita de Resultados
Escrever os resultados de volta para o S3 pode ser lento se n√£o for feito via buffer.
Ponto de Trabalho: csv.Writer com Buffer.
A√ß√£o: Sempre use writer.Flush() apenas ao final do processamento do lote e garanta que est√° escrevendo em blocos, evitando chamadas de sistema (syscalls) para cada linha de predi√ß√£o.


## Profiling 

Para ativar o Profiling em tempo real no seu servidor Go, voc√™ s√≥ precisa importar o pacote net/http/pprof e iniciar o servidor. Isso permitir√° que voc√™ veja exatamente onde o bin√°rio est√° gastando CPU (se no parser de CSV ou na predi√ß√£o do Leaves) e como a mem√≥ria est√° sendo alocada.
1. Modifica√ß√µes no main.go
```
Adicione o import (o caractere _ serve para registrar as rotas de perfil automaticamente) e inicie o servidor pprof em uma goroutine separada:
import (
	_ "net/http/pprof" // Importa√ß√£o m√°gica que registra os handlers de profiling
	"net/http"
	"fmt"
)

func main() {
	// Inicia o pprof em uma porta diferente (ex: 6060) para n√£o interferir no SageMaker
	go func() {
		fmt.Println("[DEBUG] Profiler rodando na porta 6060")
		http.ListenAndServe(":6060", nil)
	}()

	// ... seu c√≥digo original do servidor na porta 8080 ...
}
```
2. Como analisar os Gargalos (Localmente)
Com o servidor rodando e voc√™ enviando dados de teste, execute estes comandos no seu terminal:
Verificar uso de CPU
```
go tool pprof http://localhost:6060/debug/pprof/profile?seconds=30
```

Isso gera um relat√≥rio de 30 segundos. Digite top no console para ver as fun√ß√µes mais lentas.
Verificar aloca√ß√µes de Mem√≥ria (Heap):
```
go tool pprof http://localhost:6060/debug/pprof/heap
```

Use o comando svg para gerar um gr√°fico visual de onde a mem√≥ria est√° sendo "presa".
Resumo Final dos Pontos de Aten√ß√£o (Checklist de Performance)
[ ] Deserializa√ß√£o: O strconv.ParseFloat √© o seu maior suspeito de lentid√£o. Monitore-o no pprof.
[ ] Reuso de Mem√≥ria: Garanta que reader.ReuseRecord = true est√° ativo no handler.
[ ] Buffer de Escrita: O csv.NewWriter deve receber o w (ResponseWriter) e o Flush() deve ser chamado s√≥ no fim do loop.
[ ] Concorr√™ncia: Ajuste MaxConcurrentTransforms no Boto3 para saturar a CPU da inst√¢ncia ml.c5.
[ ] Logs: Remova fmt.Printf dentro do loop de predi√ß√£o; use logs apenas para erros graves.

## üõ†Ô∏è Debug e Profiling de Performance
O servidor Go inclui o `net/http/pprof` para an√°lise de gargalos.
- **Porta 8080:** Infer√™ncia (SageMaker).
- **Porta 6060:** Profiling (Apenas para ambiente de desenvolvimento).

Para analisar CPU via terminal:
`go tool pprof http://localhost:6060/debug/pprof/profile?seconds=30`

Este setup permite identificar se a lat√™ncia est√° no parser de CSV ou no c√°lculo matem√°tico do modelo.


## üõ†Ô∏è Debug e Profiling de Performance
O servidor Go inclui o `net/http/pprof` para an√°lise de gargalos.
- **Porta 8080:** Infer√™ncia (SageMaker).
- **Porta 6060:** Profiling (Apenas para ambiente de desenvolvimento).

Para analisar CPU via terminal:
`go tool pprof http://localhost:6060/debug/pprof/profile?seconds=30`

Este setup permite identificar se a lat√™ncia est√° no parser de CSV ou no c√°lculo matem√°tico do modelo.

